{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "transcript format:\n",
    "{\n",
    "    \"video_id\": \"4pa9O5cr398\",\n",
    "    \"timestamp\": \"2025-04-06T19:14:11.761808\",\n",
    "    \"status\": \"success\",\n",
    "    \"error_type\": null,\n",
    "    \"error_message\": null,\n",
    "    \"transcripts\": [\n",
    "        {\n",
    "            \"language\": \"English (auto-generated)\",\n",
    "            \"language_code\": \"en\",\n",
    "            \"is_generated\": true,\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"text\": \"hello\",\n",
    "                    \"start\": 9.28,\n",
    "                    \"duration\": 2.88\n",
    "                },\n",
    "                {\n",
    "...\n",
    "                {\n",
    "                    \"text\": \"you\",\n",
    "                    \"start\": 723.12,\n",
    "                    \"duration\": 2.08\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083943e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "sponsor_dataset = r\"C:\\Users\\caotr\\Downloads\\transcript_data\\sponsorTimes.parquet\"\n",
    "video_info_dataset = r\"C:\\Users\\caotr\\Downloads\\transcript_data\\videoInfo.csv\"\n",
    "transcript_folder = r\"C:\\Users\\caotr\\Downloads\\transcript_data\\transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ca075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(transcript_folder, sponsor_dataset):\n",
    "    # Đọc dữ liệu sponsor\n",
    "    sponsor_df = pd.read_parquet(sponsor_dataset)\n",
    "    \n",
    "    # Tạo dictionary để lưu thông tin sponsor theo video_id\n",
    "    sponsor_dict = defaultdict(list)\n",
    "    for _, row in sponsor_df.iterrows():\n",
    "        sponsor_dict[row['videoID']].append((row['startTime'], row['endTime']))\n",
    "    \n",
    "    all_segments = []\n",
    "    \n",
    "    # Đọc và xử lý từng file transcript\n",
    "    for file_name in tqdm(os.listdir(transcript_folder)):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(transcript_folder, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                transcript = json.load(f)\n",
    "            \n",
    "            video_id = transcript['video_id']\n",
    "            \n",
    "            # Kiểm tra xem transcript có dữ liệu không\n",
    "            if transcript['status'] != 'success' or not transcript['transcripts']:\n",
    "                continue\n",
    "            \n",
    "            # Lấy dữ liệu transcript\n",
    "            transcript_data = None\n",
    "            for t in transcript['transcripts']:\n",
    "                if t['language_code'] == 'en':\n",
    "                    transcript_data = t['data']\n",
    "                    break\n",
    "            \n",
    "            if not transcript_data:\n",
    "                continue\n",
    "            \n",
    "            # Xử lý từng đoạn trong transcript\n",
    "            for segment in transcript_data:\n",
    "                start_time = segment['start']\n",
    "                end_time = start_time + segment['duration']\n",
    "                text = segment['text']\n",
    "                \n",
    "                # Xác định xem đoạn này có nằm trong sponsor không\n",
    "                is_sponsor = 0\n",
    "                for sponsor_start, sponsor_end in sponsor_dict.get(video_id, []):\n",
    "                    # Nếu đoạn này nằm chủ yếu trong khoảng sponsor\n",
    "                    if (start_time >= sponsor_start and start_time < sponsor_end) or \\\n",
    "                       (end_time > sponsor_start and end_time <= sponsor_end) or \\\n",
    "                       (start_time <= sponsor_start and end_time >= sponsor_end):\n",
    "                        is_sponsor = 1\n",
    "                        break\n",
    "                \n",
    "                all_segments.append({\n",
    "                    'video_id': video_id,\n",
    "                    'start': start_time,\n",
    "                    'end': end_time,\n",
    "                    'text': text,\n",
    "                    'is_sponsor': is_sponsor\n",
    "                })\n",
    "    \n",
    "    # Tạo DataFrame từ tất cả các đoạn đã xử lý\n",
    "    segments_df = pd.DataFrame(all_segments)\n",
    "    return segments_df\n",
    "\n",
    "# Gọi hàm xử lý\n",
    "segments_df = process_transcripts(transcript_folder, sponsor_dataset)\n",
    "\n",
    "# Lưu DataFrame để sử dụng sau này\n",
    "segments_df.to_parquet('transcript_segments_labeled.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
